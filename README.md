# FlinkSummary
Tuning and knowledge summary of Flink
# Flink调优

# 资源配置调优
  1. 最优并行度设置
    1. source端：调整并行度等于数据源的分区数，例如kafka的topic分区数。如果相等了，消费速度还是跟不是数据产生速度，那么就考虑调大kafka的topic的分区数，并且调整并行度和其相等。不要让flink的并行度大于kafka的topic的分区数，这样会产生有的并行度空闲，浪费资源。
    2. Transform端：第一次keyBy之前的算子，例如map,filter,flatmap处理速度快的算子，和source保持一致就行。第一次keyBy之后的算子，可以根据压测的方法来根据keyBy算子上游的数据发送量和该算子处理数据的能力得到最优并行度。总QPS/单个并行度处理能力=并行度，最后再乘1.2，留一些富余的资源。压测的方式很简单，先在kafka中积压数据，之后开启Flink任务，出现反压，就是处理瓶颈。相当于水库先积水，一下子泄洪。数据可以是自己造的模拟数据，也可以是生产中的部分数据。
    3. sink端：sink端是数据流向下游的地方，可以根据sink端的数据量及下游的服务抗压能力进行评估。如果sink端是kafka，可以设为kafka对应topic的分区数。
  2. Checkpoint的设置
    1. 设置checkpoint的间隔时间，一般设置为分钟级，如果状态大的任务设置时间为5到10分钟
    2. 调整两次checkpoint的间隔时间，这个参数的含义是：例如checkpoint间隔时间设置为1分钟，如果checkpoint耗时40s,那么20s后就会进行下一次checkpoint，但是如果设置了两次checkpoint的间隔时间为30s, 那么不会20s之后执行，会30s之后执行。
    3. 设置 checkpoint 语义，可以设置为 EXACTLY_ONCE，表示既不重复消费也不丢数据AT_LEAST_ONCE，表示至少消费一次，可能会重复消费
    4. 设置checkpoint的超时时间，默认为10分钟，可以设置设置小一些
    5. 允许失败的次数
# 反压处理
  1. 产生场景
    通过在短时间内的负载高峰导致系统的接收数据的速率远高于它处理数据的速度。在垃圾回收的时间内消息快速的堆积。在大促，节日等场景下数据量会急速增大。如果反压不及时处理会导致资源耗尽和系统崩溃。
  2. 反压机制
  反压机制是指系统能自动检测出数据阻塞的Operator, 然后自适应的数据源发送数据的速率，从而维持整个系统的稳定。
  3. 检测方法
    1. 使用web UI的Job中的backpressure页面，其中会进行反压测试，会采样判断卡在申请缓存的次数，来确定是否出现反压，根据比例。
    2. 使用Metrics对task的inputChannel进行监控，判断是否满了。
  
# 数据倾斜
  1. 检测是否出现数据倾斜
  每个task会有很多subtask,通过Flink的Web UI 界面可以很准确的检测到分发给每个subtask的数据量，这样          就可以判断出哪个subtask出现了数据倾斜，通常数据倾斜也会引起反压。
  2. keyBy后的聚合操作存在数据倾斜
    使用两阶段聚合，在keyBy之前使用flatmap或者其他转换算子进行预聚合，然后发送到下游
  3. keyBy前出现数据倾斜
    一般是原本的数据存在数据不均匀的情况，例如Kafka的分区数据量不同，这种情况需要让 Flink 任务强制进行shuffle。使用shuffle、rebalance 或 rescale算子即可将数据均匀分配，从而解决数据倾斜的问题。
  4. keyBy之后的窗口聚合操作存在数据倾斜
    添加随机数前缀或者后缀的方法，首先给数据key加上随机数前缀，然后进行keyBy，开窗聚合.最后去掉前缀或者后缀，进行keyBy然后聚合。
  Flink的特点
  1. 高吞吐，低延迟，每秒可以处理百万级数据，可以达到毫秒级延迟
  2. 保证结果的准确性，Flink提供了事件事件和处理事件语义，使用watermark机制使乱序流和基于事件时间都可以保证准确性结果。
  3. 使用checkpoint和state来保证了精确一次。
  Flink vs Spark
  1. Spark以批处理为根本，离线的是一个大批次，实时数据就是一个一个无限的小批次。因此SparkStreaming并不是真正意义上的流，而是微批次处理。
  Flink是基于流处理为基础，认为实时数据是标准的没有界限的流
  2. Spark的底层数据模型是RDD，SparkStreaming底层接口Dstrean, Dstream实际上也就是一组组小批次的RDD集合，在计算的时候将DAG图根据宽窄依赖划分为不同的Stage，然后根据分区数划分为不同的任务进行执行。
    Flink基本数据模型是数据流DataFlow, 以事件（Event) 为序列。标准的流式处理流程，一个节点处理完就发送到下一个节点进行处理。
